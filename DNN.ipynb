{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "from torchmetrics import SymmetricMeanAbsolutePercentageError\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/All_music.csv')\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df.drop(\"Unnamed: 0\",inplace=True,axis=1)\n",
    "df.set_index(\"timestamp\",inplace=True)\n",
    "\n",
    "df = df[\"2020-12-14\":]\n",
    "\n",
    "df[\"dayofweek\"] = df.index.dayofweek.astype(\"int32\")\n",
    "df[\"log_views\"] = np.log(df[\"views\"] + 1e-8)\n",
    "df[\"month\"] = df.index.month.astype(\"int32\")\n",
    "df[\"year\"] = df.index.year.astype(\"int32\")\n",
    "df[\"avg_by_song_month\"] = df.groupby([\"month\",\"year\",\"article\"],observed=True)[\"views\"].transform(\"mean\").astype(\"float64\")\n",
    "df[\"min_by_song_month\"] = df.groupby([\"month\",\"year\",\"article\"],observed=True)[\"views\"].transform(\"min\").astype(\"float64\")\n",
    "df[\"max_by_song_month\"] = df.groupby([\"month\",\"year\",\"article\"],observed=True)[\"views\"].transform(\"max\").astype(\"float64\")\n",
    "\n",
    "features = [\"dayofweek\", \"month\", \"year\", \"min_by_song_month\", \"max_by_song_month\", \"avg_by_song_month\",\"log_views\"]\n",
    "target = \"views\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicDataset(Dataset):\n",
    "    def __init__(self,features,target):\n",
    "        self.feature = features\n",
    "        self.target = target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        item = self.feature[idx]\n",
    "        label = self.target[idx]\n",
    "        \n",
    "        return item,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator='gpu', \n",
    "    devices=1,\n",
    "    gradient_clip_val=0.1,\n",
    "    #limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    limit_train_batches=1.0, #if set to 1.0 gather all training data, default.\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    ")\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, shuffle=True)\n",
    "\n",
    "train_x = torch.tensor(train[features].values).to(device)\n",
    "train_y = torch.tensor(train[target].values).unsqueeze(1).to(device)\n",
    "test_x = torch.tensor(test[features].values).to(device)\n",
    "test_y = torch.tensor(test[target].values).unsqueeze(1).to(device)\n",
    "\n",
    "train = MusicDataset(train_x,train_y)\n",
    "valid = MusicDataset(test_x,test_y)\n",
    "\n",
    "train_loader = DataLoader(train,shuffle=False)\n",
    "valid_loader = DataLoader(valid,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal learning rate\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.activ1 = nn.ReLU()\n",
    "        self.layer_2 = nn.Linear(hidden_dim, 1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.activ1(x)\n",
    "        x = self.layer_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def smape(target, forecast):\n",
    "  if type(target) == pd.core.frame.DataFrame:\n",
    "    target = target.values\n",
    "\n",
    "  denominator = np.abs(target) + np.abs(forecast)\n",
    "  flag = denominator == 0.\n",
    "\n",
    "  smape = 2 * np.mean(\n",
    "      (np.abs(target - forecast) * (1 - flag)) / (denominator + flag)\n",
    "  )\n",
    "  return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Loss: 0.960506021976471\n",
      "epoch: 0, Loss: 0.3504444360733032\n",
      "epoch: 0, Loss: 0.08003087341785431\n",
      "epoch: 0, Loss: 0.06884255260229111\n",
      "epoch: 0, Loss: 0.8303112387657166\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MOHAMM~1\\AppData\\Local\\Temp/ipykernel_6436/297425633.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\MOHAMM~1\\AppData\\Local\\Temp/ipykernel_6436/297425633.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(train_dl, model)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;31m# credit assignment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m# update model weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "def train_model(train_dl, model):\n",
    "    # define the optimization\n",
    "    criterion = SymmetricMeanAbsolutePercentageError().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1.1220184543019632e-05)\n",
    "    # enumerate epochs\n",
    "    for epoch in range(100):\n",
    "        # enumerate mini batches\n",
    "        running_loss = 0\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            #Decay Learning Rate\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            yhat = model(inputs.float().to(device)).to(device)\n",
    "            # calculate loss\n",
    "            loss = criterion(yhat.float(), targets.float()).to(device)\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:\n",
    "                print(f\"epoch: {epoch}, Loss: {running_loss}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "# evaluate the model\n",
    "def evaluate_model(test_dl, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        yhat = model(inputs.float()).to(device)\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.cpu().detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        # round to class values\n",
    "        yhat = yhat.round()\n",
    "        # store\n",
    "        predictions.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = np.vstack(predictions), np.vstack(actuals)\n",
    "    # calculate accuracy\n",
    "    return smape(actuals, predictions)\n",
    "\n",
    "\n",
    "# make a class prediction for one row of data\n",
    "def predict(row, model):\n",
    "    # convert row to data\n",
    "    row = torch.Tensor([row])\n",
    "    # make prediction\n",
    "    yhat = model(row)\n",
    "    # retrieve numpy array\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat\n",
    "\n",
    "n_input = len(features)\n",
    "n_hidden = 15\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = NeuralNetwork(n_input,n_hidden).to(device)\n",
    "train_model(train_loader,model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7baccf88227eab4c3a997091e3b8cad5657bd0277ceacd9564be0b0f999d1db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
