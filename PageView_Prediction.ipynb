{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from urllib import parse\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://wikimedia.org/api/rest_v1/\"\n",
    "HEADERS = {\"Accept\":\"application/json\",\"user-agent\":\"test123@gmail.com\"}\n",
    "SESSION = requests.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pageviews(article: str, start: datetime, end: datetime, project=\"en.wikipedia.org\",\n",
    "                  access=\"all-access\", agent=\"all-agents\", granularity=\"daily\"):\n",
    "    \"\"\"\n",
    "        args:\n",
    "            article: The name of the article\n",
    "            start: Start date \n",
    "            end: End date\n",
    "            project: The domain, default en.wikipedia.org\n",
    "            access: Type of the device, default all-access. other options(Desktop, mobile-app, mobile-web)\n",
    "            agent: Type of the agent, default all-agents. other options(user, spider, automated)\n",
    "            granularity: The time unit, default daily. Other options(monthly)\n",
    "            \n",
    "    \"\"\"\n",
    "    params = [\n",
    "        \"metrics\",\n",
    "        \"pageviews\",\n",
    "        \"per-article\",\n",
    "        project.capitalize(),\n",
    "        access,\n",
    "        agent,\n",
    "        parse.quote(article),\n",
    "        granularity,\n",
    "        start.strftime(\"%Y%m%d\"),\n",
    "        end.strftime(\"%Y%m%d\")\n",
    "    ]\n",
    "    url = URL + \"/\".join(params)\n",
    "    return SESSION.get(url,headers=HEADERS).json()[\"items\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_pageviews(title, genre: str, data):\n",
    "    \"\"\"\n",
    "        args:\n",
    "            genre: options (Games,Film and TV, Literary, Music)\n",
    "    \"\"\"\n",
    "    if genre.lower() not in [\"games\", \"film and tv\", \"literary\", \"music\"]:\n",
    "        raise ValueError(\n",
    "            \"Genre must be an element of [Games, Film and TV, Literary, Music]\")\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%Y%m%d%H\",)\n",
    "    if not os.path.isdir(\"Data\"):\n",
    "        os.mkdir(\"Data\")\n",
    "    df.to_excel(\"Data/\" + genre +\n",
    "                \"/\" + title + \".xlsx\", index=False)\n",
    "\n",
    "\n",
    "def fetch_data_sources(page, filename):\n",
    "    url = \"https://www.wikitable2json.com/api/\" + \\\n",
    "        page\n",
    "\n",
    "    params = {\"cleanRef\": \"true\", \"lang\": \"en\"}\n",
    "    request = SESSION.get(url=url, params=params, headers=HEADERS)\n",
    "    resposne = request.json()\n",
    "    table = np.squeeze(resposne)\n",
    "    data = {}\n",
    "    for i in range(len(table[0])):\n",
    "      data[table[0, i]] = table[1:, i].tolist()\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel(\"Data/\" + filename + \".xlsx\", index=False)\n",
    "\n",
    "fetch_data_sources(\"List_of_video_games_considered_the_best\", \"Games_sources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(\"Data/Games_sources.xlsx\")\n",
    "# df = df[df[\"Year\"] >= 2000 ]\n",
    "# for year,game in df.values[:,0:2]:\n",
    "#     print(game,year)\n",
    "#     if year < 2005:\n",
    "#         year = 2005\n",
    "#     data = get_pageviews(game,datetime(year,1,1),datetime(2020,1,1))\n",
    "#     store_pageviews(game,\"Games\",data)\n",
    "\n",
    "# dfs = []\n",
    "# for file in os.listdir(\"Data/Games\"):\n",
    "#     if file.endswith(\".xlsx\"):\n",
    "#         df = pd.read_excel(\"Data/Games/\"+file)\n",
    "#         dfs.append(df)\n",
    "# new_df = pd.concat(dfs)\n",
    "# new_df.to_excel(\"Data/All_Games.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7baccf88227eab4c3a997091e3b8cad5657bd0277ceacd9564be0b0f999d1db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
